setwd("C:/Users/LUIS/SkyDrive/Documents/R.code/GetCleanData")
library(bitops)
library (RCurl)
library (XML)
library(bitops)
library (RCurl)
library (XML)
temp <- getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", ssl.verifyPeer=FALSE)
DFX <- xmlTreeParse(temp,useInternal = TRUE)
DFX
require(XML)
xmlData <- xmlToList(DFX)
require(XML)
xmlData
location <- as.list(xmlData[["response"]][["row"]][["row _address"]][["zipcode"]])
location
class(location)
loca <- as.list(xmlData[["response"]][["row"]][["row _address"]][["zipcode"]])
class(loca)
View(loca)
library(XML)
require(XML)
data <- xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
xml_data <- xmlToList(data)
xml_data
location <- as.list(xml_data[["data"]][["location"]][["point"]])
location
View(location)
loca <- as.list(xmlData[["response"]][["row"]][["row"]])
loca
loca <- as.list(xmlData[["response"]][["row"]][["zipcode"]])
loca
location <- as.list(xml_data[["data"]][["location"]][["height"]])
location
location <- as.list(xml_data[["data"]][["location"]][["area-description"]])
location
location <- as.list(xml_data[["data"]][["location"]][["location-key"]])
location
loca <- as.list(xmlData[["response"]][["row"]][["name"]])
loca
loca <- as.list(xmlData[["response"]][["row"]][["row"]][["zipcode"]])
loca
loca <- as.list(xmlData[["row"]][["row"]][["zipcode"]])
loca
out <- data.frame(
as.list(loca))
head(out)
loca <- as.list(xmlData[["row"]][["row"]][["name"]])
loca
loca <- as.list(xmlData[["row"]][["row"]][["neighborhood"]])
loca
loca <- as.list(xmlData[["row"]][["row"]][["location_1"]])
loca
loca <- as.list(xmlData[["row"]][["row"]])
loca
loca <- as.list(xmlData[["row"]][["row"]][["location_1"]])
loca <- as.list(xmlData[["row"]][["row"]][["location_1"]])
loca
loca <- as.list(xmlData[["row"]][["row"]][["zipcode"]])
loca
start_time <- unlist(xmlData[["row"]][["zipcode"]][
names(xmlDdata[["row"]][["zipcode"]]) == "zipcode"])
start_time <- unlist(xmlData[["row"]][["zipcode"]][
names(xmlData[["row"]][["zipcode"]]) == "zipcode"])
out <- data.frame(
as.list(loca))
head(out)
out <- data.frame(
as.list(loca),
"zip" = start_time)
loca <- as.list(xmlData[["row"]][["row"]][["zipcode"]])
start_time <- unlist(xmlData[["row"]][["zipcode"]][
names(xmlData[["row"]][["zipcode"]]) == "zipcode"])
out <- data.frame(
as.list(loca),
"zipcode" = start_time)
location
library(XML)
require(XML)
data <- xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
xml_data <- xmlToList(data)
location <- as.list(xml_data[["data"]][["location"]][["point"]])
location
start_time <- unlist(xml_data[["data"]][["time-layout"]][
names(xml_data[["data"]][["time-layout"]]) == "start-valid-time"])
temps <- xml_data[["data"]][["parameters"]]
temps <- temps[names(temps) == "temperature"]
temps <- temps[sapply(temps, function(x) any(unlist(x) == "hourly"))]
temps <- unlist(temps[[1]][sapply(temps, names) == "value"])
out <- data.frame(
as.list(location),
"start_valid_time" = start_time,
"hourly_temperature" = temps)
head(out)
library(XML)
datahere = "~/"
setwd(datahere)
download.file("http://www.newyorkfed.org/markets/pomo/xml/v3_0/pomoXML.cfm?SHOWMORE=TRUE&date1=01/01/2009&date2=01/10/2009",paste(datahere,"feddata.xml",sep=""))
tt = xmlParse("feddata.xml")
out <- getNodeSet(tt, "//*[name()='out:issue']", fun=xmlToList)
df <- data.frame(do.call(rbind, out))
head(df)
library(XML)
datahere = "~/"
setwd(datahere)
download.file("http://www.newyorkfed.org/markets/pomo/xml/v3_0/pomoXML.cfm?SHOWMORE=TRUE&date1=01/01/2009&date2=01/10/2009",paste(datahere,"feddata.xml",sep=""))
tt = xmlParse("feddata.xml")
out <- getNodeSet(tt, "//*[name()='out:issue']", fun=xmlToList)
df <- data.frame(do.call(rbind, out))
head(df)
library(XML)
datahere = "~/"
setwd(datahere)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml",paste(datahere,"feddata.xml",sep=""))
tt = xmlParse("feddata.xml")
out <- getNodeSet(tt, "//*[name()='out:issue']", fun=xmlToList)
df <- data.frame(do.call(rbind, out))
head(df)
library(bitops)
library (RCurl)
library (XML)
temp <- getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", ssl.verifyPeer=FALSE)
DFX <- xmlTreeParse(temp,useInternal = TRUE)
tt = xmlParse("DFX")
out <- getNodeSet(tt, "//*[name()='out:issue']", fun=xmlToList)
df <- data.frame(do.call(rbind, out))
head(df)
tt = xmlParse(DFX)
out <- getNodeSet(tt, "//*[name()='out:issue']", fun=xmlToList)
df <- data.frame(do.call(rbind, out))
head(df)
library(bitops)
library (RCurl)
library (XML)
temp <- getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", ssl.verifyPeer=FALSE)
DFX <- xmlTreeParse(temp,useInternal = TRUE)
DFX
setwd("C:/Users/LUIS/SkyDrive/Documents/R.code/GetCleanData")
library(bitops)
library (RCurl)
library (XML)
temp <- getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", ssl.verifyPeer=FALSE)
DFX <- xmlTreeParse(temp,useInternal = TRUE)
aa <- xmlSApply(doc[[1]], xmlValue)
aa <- xmlSApply(DFX[[1]], xmlValue)
row = as.data.frame(matrix(as.numeric(tmp[,-1]), 2))
names(row) = names(DFX[[1]])[-1]
row$zipcode = tmp[,1]
library(bitops)
library (RCurl)
library (XML)
temp <- getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", ssl.verifyPeer=FALSE)
DFX <- xmlTreeParse(temp,useInternal = TRUE)
tt = xmlParse(DFX)
out <- getNodeSet(tt, "//*[name()='out:issue']", fun=xmlToList)
df <- data.frame(do.call(rbind, out))
head(df)
DFX
tt
tt
temp <- getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", ssl.verifyPeer=FALSE)
tt = xmlParse(temp)
tt
out <- getNodeSet(tt, "//*[name()='out:issue']", fun=xmlToList)
out
temp <- getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", ssl.verifyPeer=FALSE)
tt = xmlParse(temp)
out <- getNodeSet(tt, "//*[name()='out:issue']", fun=xmlToList)
df <- data.frame(do.call(rbind, out))
head(df)
library(XML)
datahere = "~/"
setwd(datahere)
download.file("http://www.newyorkfed.org/markets/pomo/xml/v3_0/pomoXML.cfm?SHOWMORE=TRUE&date1=01/01/2009&date2=01/10/2009",paste(datahere,"feddata.xml",sep=""))
tt = xmlParse(temp)
out <- getNodeSet(tt, "//*[name()='out:issue']", fun=xmlToList)
df <- data.frame(do.call(rbind, out))
head(df)
library(XML)
datahere = "~/"
setwd(datahere)
download.file("http://www.newyorkfed.org/markets/pomo/xml/v3_0/pomoXML.cfm?SHOWMORE=TRUE&date1=01/01/2009&date2=01/10/2009",paste(datahere,"feddata.xml",sep=""))
tt = xmlParse("feddata.xml")
out <- getNodeSet(tt, "//*[name()='out:issue']", fun=xmlToList)
df <- data.frame(do.call(rbind, out))
head(df)
tt
out
df
library(bitops)
library (RCurl)
library (XML)
temp <- getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", ssl.verifyPeer=FALSE)
DFX <- xmlTreeParse(temp,useInternal = TRUE)
DFX
outt <- getNodeSet(DFX, "//*[name()='out:issue']", fun=xmlToList)
outt
DFX
outt <- getNodeSet(DFX, "//*[name()='out:issue']", fun=xmlToList)
outt
out
View(out)
tt
require(XML)
xmlData <- xmlToList(DFX)
xmlData
tt
out
library(XML)
library(plyr)
doc <- ldply(xmlData$DataSet$Group, function(d){
if ("issue" %in% names(d)){
d$issue
} else {
NULL
}
})
doc
doc <- ldply(xmlData$row$roww, function(d){
if ("issue" %in% names(d)){
d$issue
} else {
NULL
}
})
doc
doc <- ldply(xmlData$row$row, function(d){
if ("issue" %in% names(d)){
d$issue
} else {
NULL
}
})
doc
xmlData
doc <- ldply(xmlData$row$row$zipcode, function(d){
if ("issue" %in% names(d)){
d$issue
} else {
NULL
}
})
xmlData
doc
DFX
xpathApply(DFX, "//level4name", xmlValue)
xpathApply(DFX, "//zipcode", xmlValue)
?xpathApply
zip <- xpathApply(DFX, "//zipcode", xmlValue)
zip
nrow(zip)
class(zip)
length(zip)
wt$count <- sapply(zip, function(x) sum(str_count(x, "21231")))
library(stringr)
wt <- data.frame(lineNum = 1:length(zip))
wt$count <- sapply(zip, function(x) sum(str_count(x, "21231")))
wt$count
class(wt$count)
View(wt$count)
code <- sapply(zip, function(x) sum(str_count(x, "21231")))
View(code)
nrow(code)
length(code)
zz <- unlist(code)
class(zz)
zz
zz <- do.call(c,list(code))
zz
class(zz)
as.vector(code)
zz <- as.vector(code)
zz
class(zz)
?unlist()
zz <- unlist(code, recursive = FALSE)
zz
zz <- unlist(code, recursive = TRUE)
ZZ
zz <- unlist(code, recursive = FALSE)
zz <- unlist(code, recursive = FALSE)
zz
class(zz)
zz <- unlist(code)
zz
?as.data.frame
zz <- as.data.frame(code)
zz
class(zz)
yy <- as.vector(zz)
yy
class(yy)
nrow(zz)
length(unique(1))
length(unique(0))
nrow(table(zz$x))
table(zz$x)
zz
View(zz)
table(zz$code)
df <- as.data.frame(code)
table(df$code)
table(zz$code)
load("C:/Users/LUIS/SkyDrive/Documents/R.code/.RData")
table(zz$code)
utils:::menuInstallPkgs()
library(matrixStats)
library(matrixStats)
q()
require(httr)
require(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("github","816f064becc30c36a06d","b717ca2ef28c85ab8bf42971cacf23550432483b")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp,cache=FALSE)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
utils:::menuInstallPkgs()
library(Hmisc)
utils:::menuInstallPkgs()
library(dplyr)
library(dplyr)
q()
setwd("C:/Dev/Git/RepData_PeerAssessment2")
data <- download.file('https://class.coursera.org/repdata-014/human_grading/view/courses/973515/assessments/4/submissions')
dim(data)
?download.file
require(utils)
require(utils)
require(utils)
url = 'https://class.coursera.org/repdata-014/human_grading/view/courses/973515/assessments/4/submissions'
data <- download.file(url, destfile=StormData.csv)
require(curl)
require(Curl)
require(RCurl)
require(utils)
require(RCurl)
url = 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
data <- download.file(url, destfile=StormData.csv, method='curl')
require(utils)
require(RCurl)
url = 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
data = getURL(url)
require(utils)
require(RCurl)
url = 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
data <- download.file(url, destfile='StormData.csv', method='libcurl')
require(utils)
require(RCurl)
url = 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
data <- download.file(url, destfile='StormData.csv', method='libcurl')
data <- download.file(url, destfile='StormData.csv', method='curl')
require(utils)
require(RCurl)
url = 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
data <- download.file(url, destfile='StormData.csv', method='curl')
require(utils)
require(RCurl)
url = 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
data = getURL(url)
url = 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
data = getURL(url, ssl.verifypeer=FALSE)
url = 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
data = read.csv(file=url) #, ssl.verifypeer=FALSE
url = 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
data = read.csv(file=url, setInternet2=TRUE) #, ssl.verifypeer=FALSE
url = 'http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2'
data = read.csv(file=url) #, ssl.verifypeer=FALSE
dim(data)
View(data)
